---
title             : "Estimating evidential value from ANOVA summaries: A comment on Ly et al. (2018)"
shorttitle        : "Estimating evidential value from ANOVA"

author: 
  - name          : "Thomas J. Faulkenberry"
    corresponding : yes    
    address       : "Department of Psychological Sciences, Box T-0820, Tarleton State University, Stephenville, TX 76401"
    email         : "faulkenberry@tarleton.edu"
 

affiliation:
  - institution   : "Tarleton State University"
  
bibliography      : ["../references.bib"]

figsintext        : yes
figurelist        : no
tablelist         : no
footnotelist      : no
lineno            : no

lang              : "english"
class             : "man"
output            : papaja::apa6_pdf
---

```{r start, include = FALSE}
library(papaja)
```

The last decade has witnessed a tremendous increase in the number of tools that enable social science researchers to perform Bayesian inference. @ly2018 recently described one such tool included as part of the open-source software package JASP -- the Summary Stats module [@jasp]. With this tool, researchers can input a minimal set of summary statistics (either from their own previously-run analysis or from the already published results of others) and obtain a Bayesian re-evaluation of the results. In particular, the Summary Stats module reports the Bayes factor [@kass1995], a continuous index of the extent to which observed data are more likely under one hypothesis (e.g., the null hypothesis $\mathcal{H}_0$) over another competing hypothesis (e.g., the alternative hypothesis $\mathcal{H}_1$). As a part of the Bayesian inferential framework, this Bayes factor (denoted $B_{01}$) describes the factor by which our prior relative belief between $\mathcal{H}_0$ and $\mathcal{H}_1$ should be updated after observing data. This characterization makes the Bayes factor a useful measure of the *evidential value* of data [@etz2017].

As @ly2018 do an excellent job of describing, the JASP Summary Stats module is a powerful tool that gives the user access to some of the core elements of Bayesian inference without need for accompanying raw data. This provides users with flexibility; researchers may wish assess the evidential value of their own data to sensibly ground their interpretations, and reviewers/editors may wish to do the same for reported data to help with their own interpretations and decisions regarding publication. However, at present the Summary Stats module does not include an option for directly reanalyzing the results of an analysis of variance (ANOVA). ANOVA is often characterized as the "workhorse" of experimental psychology [@rouder2016]. Thus, it would be quite helpful to the "academic consumer" to be able to to compute Bayes factors from minimal ANOVA summaries.

To this end, I wrote an interactive web application for calculating Bayes factors from minimal single factor ANOVA summaries (see Figure 1). The application, which can accessed by any web browser at http://tomfaulkenberry.shinyapps.io/anovaBFcalc, performs calculations that are based on the BIC method [@masson2011;@wagenmakers2007;@faulkenberry2018;@nathoo2016;@faulkenberry2019]. It requires minimal input; the user need only specify the $F$ statistic and the degrees of freedom for the ANOVA. Additionally, the user may specify the design (between-subjects or repeated measures) and a prior probability for $\mathcal{H}_0$ (default = 0.5). In return, the application provides the user with estimates of $B_{01}$ and $B_{10}$, a sentence interpreting what the Bayes factor means, and estimates of the posterior probability of each hypothesis. 

![An interactive Bayes factor calculator, which can be accessed at http://tomfaulkenberry.shinyapps.io/anovaBFcalc. When provided minimal summary statistics from an ANOVA (e.g., the $F$ statistic and the degrees of freedom), the calculator displays Bayes factors and posterior probabilities for $\mathcal{H}_0$ and $\mathcal{H}_1$, as well as a "pizza plot" [@wagenmakers2017] showing the relative extent to which $\mathcal{H}_0$ and $\mathcal{H}_1$ predict the observed data. Note that the pizza plot reflects the Bayes factor, not the posterior probabilities of $\mathcal{H}_0$ and $\mathcal{H}_1$.](fig1.pdf){ width=75%}

To illustrate the use of the online calculator, let us consider the following results from @rovenpor2019. In several experiments, @rovenpor2019 investigated whether violent conflict provides people with an enduring sense of meaning, thus perpetuating further intergroup conflict. In one study (Study 4), they measured perceptions of the scope of conflict as a function of whether participants first wrote about the conflict. @rovenpor2019 reported no significant difference between groups, $F(1,226)=2.17$, $p=0.143$. Though @rovenpor2019 interpreted this as a null effect, a strictly frequentist framework gives no indication of the degree of support for $\mathcal{H}_0$. As Figure 1 displays, the Bayes factor calculator gives additional information that may help to assess the evidential value of this result. First, we see that $B_{01}=5.08$, indicating that the observed data are approximately 5.08 times more likely under $\mathcal{H}_0$ than $\mathcal{H}_1$. Further, we see that the posterior probability for $\mathcal{H}_0$ is 0.8355. That is, observing these data increases the plausibility of $\mathcal{H}_0$ from 50% (prior) to 83.55% (posterior). The user can specify other values for the prior probability of $\mathcal{H}_0$. For example, someone skeptical of the manipulation's effect might assign a high prior probability, say $p(\mathcal{H}_0)=0.80$. The resulting posterior probability for $\mathcal{H}_0$ is 0.9531; observing these data have *increased* this user's belief in $\mathcal{H}_0$. Alternatively, someone who believes the manipulation is effective might assign $p(\mathcal{H}_0)=0.20$. In this case, the posterior probability for $\mathcal{H}_0$ is 0.5595; this user's belief has also been shifted toward belief in $\mathcal{H}_0$. Of course, this is a natural consequence of the Bayes factor, which by definition is the factor by which prior odds are multiplied after observing data.

Sometimes, Bayesian reanalyses can reveal less evidence than might be originally thought. In Study 5 of @rovenpor2019, a large sample of participants ($N=352$) were randomly assigned to one of three conditions; in two of the non-control conditions, participants watched a video about a terrorist attack, one of which framed the attack as "meaningful". Each participant was then given a series of questionnaire assessing perceptions of meaning in conflict. The authors reported a significant difference in perceived meaning of conflict, $F(2,349)= 6.21$, $p=0.002$. Traditionally, this would be viewed as support for $\mathcal{H}_1$. However, the interactive Bayes factor calculator gives $B_{10}=1.34$, indicating that the observed data is only 1.34 times more likely under $\mathcal{H}_1$ than $\mathcal{H}_0$. Equivalently, the plausibility of $\mathcal{H}_1$ is only increased from 50% (prior) to 57.22% (posterior). The Bayesian reanalysis indicates that the observed data are not very evidential; that is, they do not sway belief toward either model very strongly. 

In summary, the interactive Bayes factor calculator provides a useful supplement to the tools described by @ly2018 for assessing evidential value from studies. Like the JASP Summary Stats module, the calculator requires only minimal input, so it is easy for the user to obtain a measure of evidential value from minimal ANOVA summaries. In addition, the calculator provides interpretation of the Bayes factor, which may be useful to users who are new to using Bayesian inference [see also @vanDoorn2019]. 

One potential downside to the calculator is that the computations are based on a very specific choice of prior (the unit information prior). This prior is distributed over a large range of possible effects; on one hand, such a prior lets "the data speak for itself" [@gelman,p. 51], but on the other hand, the resulting Bayes factors are often inflated for $\mathcal{H}_0$ and undersized for $\mathcal{H}_1$. Because of this, one may wonder how the BIC prior performs compared to other default priors such as the JZS prior [@rouder2012]. It turns out that the two approaches are quite comparable, as @faulkenberry2018 demonstrated with a wide range of simulated datasets.  

There are a few advantages that the calculator (and the BIC method more generally) provide over some existing options. One is that the calculator works for repeated measures designs. Though R users can use the \texttt{oneWayAOV.Fstat} function from the BayesFactor package [@BF] to calculate Bayes factors from summary statistics, this function only works for balanced, between-subjects designs. I will note that while the calculator works with unbalanced single-factor designs (in single factor designs, the $SS$ calculations work out the same whether the design is balanced or unbalanced), it is currently an active area of investigation to see how these techniques extend to more general designs (unbalanced designs with multiple factors, etc.). In light of these comments, I think the the calculator will be useful to many people, especially as a supplement to the existing tools and emerging recommendations on conducting and reporting Bayesian analyses.

## Author Contributions
T. Faulkenberry is the sole author of this article and is responsible for its content.

## Declaration of Conflicting Interests
The author declared that there were no conflicts of interest with respect to the authorship or the publication of this article.

## Data, Materials, and Online Resources
The source code for the interactive Bayes factor calculator described in this paper can be accessed at http://github.com/tomfaulkenberry/anovaBFcalc. 

\newpage

# References

\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}
